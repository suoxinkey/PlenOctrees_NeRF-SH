{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from os import mkdir\n",
    "from apex import amp\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append('..')\n",
    "from config import cfg\n",
    "from data import make_data_loader, make_data_loader_view\n",
    "from engine.trainer import do_train\n",
    "from modeling import build_model\n",
    "from solver import make_optimizer, WarmupMultiStepLR,build_scheduler\n",
    "from layers import make_loss\n",
    "\n",
    "from utils.logger import setup_logger\n",
    "\n",
    "#from utils import vis_density\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from layers.RaySamplePoint import RaySamplePoint\n",
    "from engine import render\n",
    "import numpy as np \n",
    "torch.cuda.set_device(2)\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from imageio_ffmpeg import write_frames\n",
    "import trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_density(model,bbox, L= 32):\n",
    "\n",
    "    maxs = torch.max(bbox, dim=0).values\n",
    "    mins = torch.min(bbox, dim=0).values\n",
    "\n",
    "\n",
    "    x = torch.linspace(mins[0],maxs[0],steps=L).cuda()\n",
    "    y = torch.linspace(mins[1],maxs[1],steps=L).cuda()\n",
    "    z = torch.linspace(mins[2],maxs[2],steps=L).cuda()\n",
    "    grid_x ,grid_y,grid_z = torch.meshgrid(x, y,z)\n",
    "    xyz = torch.stack([grid_x ,grid_y,grid_z], dim = -1)  #(L,L,L,3)\n",
    "\n",
    "    xyz = xyz.reshape((-1,3)) #(L*L*L,3)\n",
    "\n",
    "\n",
    "    xyzs = xyz.split(5000, dim=0)\n",
    "\n",
    "    sigmas = []\n",
    "    for i in xyzs:\n",
    "        with torch.no_grad():\n",
    "            _,density = model.spacenet_fine(i, None, model.maxs, model.mins) #(L*L*L,1)\n",
    "            density = torch.nn.functional.relu(density)\n",
    "            sigmas.append(density.detach().cpu())\n",
    "\n",
    "    sigmas = torch.cat(sigmas, dim=0)\n",
    "\n",
    "    return sigmas,xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder = '/data/wmy/NR/RF_training/panganqi_near_far_ori'\n",
    "epoch = 834000\n",
    "para_file = 'rfnr_model_%d.pth' % epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder = '/data/wmy/NR/RF_training/plant'\n",
    "epoch = 714000\n",
    "para_file = 'rfnr_model_%d.pth' % epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.merge_from_file(os.path.join(training_folder,'configs.yml'))\n",
    "cfg.MODEL.BOARDER_WEIGHT = 1e-10\n",
    "cfg.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1\n",
      "load 56 Ts, 56 Ks, 1 frame, 400876 vertices\n",
      "dataset initialed. near: 3.008136  far: 12.583911\n",
      "0 / 1\n",
      "load 56 Ts, 56 Ks, 1 frame, 400876 vertices\n",
      "dataset initialed. near: 3.008136  far: 12.583911\n",
      "load 25684800 rays.\n"
     ]
    }
   ],
   "source": [
    "val_loader, dataset_val = make_data_loader_view(cfg, is_train=False)\n",
    "train_loader, dataset = make_data_loader(cfg, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(cfg).cuda()\n",
    "model.load_state_dict(torch.load(os.path.join(training_folder,para_file),map_location='cpu'))\n",
    "model.eval()\n",
    "model.cuda()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.5053,  -6.6616, -10.9217],\n",
       "        [  1.0823,  -6.6616, -10.9217],\n",
       "        [  1.0823,  -1.7790, -10.9217],\n",
       "        [ -0.5053,  -1.7790, -10.9217],\n",
       "        [ -0.5053,  -6.6616,  -9.1911],\n",
       "        [  1.0823,  -6.6616,  -9.1911],\n",
       "        [  1.0823,  -1.7790,  -9.1911],\n",
       "        [ -0.5053,  -1.7790,  -9.1911]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.bbox[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 512\n",
    "sigma,xyzs = vis_density(model, dataset.bbox[0], L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d082d4c7662c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mraw_xyz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxyzs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mraw_xyz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "raw = sigma.detach().cpu().numpy()\n",
    "raw_xyz = xyzs.detach().cpu().numpy()\n",
    "raw = np.reshape(raw, (L,L,L,-1))\n",
    "raw_xyz = np.reshape(raw_xyz, (L,L,L,-1))\n",
    "sigma = np.maximum(raw[...,-1], 0.)\n",
    "\n",
    "print(sigma.shape)\n",
    "print(raw_xyz.shape)\n",
    "plt.hist(np.maximum(0,sigma.ravel()), log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mcubes\n",
    "\n",
    "threshold = 50.\n",
    "print('fraction occupied', np.mean(sigma > threshold))\n",
    "vertices, triangles = mcubes.marching_cubes(sigma, threshold)\n",
    "print('done', vertices.shape, triangles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxs = torch.max(dataset.bbox[0], dim=0).values.numpy()\n",
    "mins = torch.min(dataset.bbox[0], dim=0).values.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices_n = vertices / L\n",
    "for i in range(3):\n",
    "    vertices_n[:,i] = vertices_n[:,i]*(maxs[i]-mins[i]) + mins[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = trimesh.Trimesh(vertices_n , triangles)\n",
    "mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = mesh.export(file_type='obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xzq.obj','w') as f:\n",
    "    f.write(export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = raw_xyz[sigma[:,:,:]>50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('pts.txt',pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
